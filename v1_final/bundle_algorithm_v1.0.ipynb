{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db391e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Lab/Users/AlexG/infrastructure-work/software/artificial-retina-software-pipeline-gits/master/artificial-retina-software-pipeline/utilities/electrode_map/electrode_map.py:517: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  LITKE_512_ARRAY_ADJ_MAT = np.array([\n",
      "/Volumes/Lab/Users/AlexG/infrastructure-work/software/artificial-retina-software-pipeline-gits/master/artificial-retina-software-pipeline/utilities/electrode_map/electrode_map.py:1552: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  LITKE_519_ARRAY_ADJ_MAT = np.array([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.core.display import display, HTML\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.pyplot import cm\n",
    "from scipy import linalg\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import networkx as nx\n",
    "\n",
    "# LAB LIBRARIES\n",
    "import bin2py\n",
    "import visionloader as vl\n",
    "import sta_utils as su\n",
    "import old_labview_data_reader as oldlv\n",
    "import eilib_new as eil\n",
    "\n",
    "# CUSTOM FUNCTIONS\n",
    "from scripts.bundle_algo_base import *\n",
    "from scripts.data_utils import *\n",
    "from scripts.estim_viz import *\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb7593",
   "metadata": {},
   "source": [
    "# How to run bundle algorithm code\n",
    "\n",
    "## Information about algorithm\n",
    "Axon bundle activation thresholds were determined by an automated method based on a previously described algorithm (Tandon et al. 2021), modified accordingly to avoid bias resulting from differences in array geometries (this work used a smaller, hexagonal array whereas the algorithm described in Tandon et al. 2021 was developed using a larger, rectangular array) and axon spike amplitude differences between central and peripheral RGCs. For each preparation, a threshold voltage was first determined to assign electrodes as recording significant axonal signals in response to electrical stimulation. For each RGC recorded during white noise visual stimulation, the electrodes recording axonal signals were identified as described above and the average axonal spike amplitude was determined. The median axonal spike amplitude across all recorded RGCs was computed and was taken to be the threshold voltage. Next, to determine the bundle activation threshold, for each stimulus current applied, electrodes were first identified as either activated or inactivated, depending on whether the recorded signal was above the threshold voltage. Activity on the array was identified as an axon bundle activation event when the activated electrodes resulted in a contiguous path reaching at least two non-adjacent edges of the electrode array. The bundle activation threshold, therefore, is defined as the minimum stimulation current at which a bundle event was evoked, through a binary search over all the applied current amplitudes.\n",
    "\n",
    "\n",
    "\n",
    "## For specific test cases\n",
    "\n",
    "1. Modify .scripts.data_utils.get_bundle_test_cases() to include relevant test cases\n",
    "2. Run get_dataset_dict() to get info about all datasets\n",
    "3. Run pregen_dataset_params() to get relevant dataset info from where the test cases belong\n",
    "4. Run get_bundle_test_cases() to get tests cases info\n",
    "5. Run pregen_elec_params(tests, dataset_params, dataset_path_dict...) to get params. Note: Parameters of a particular dataset-electrode pair are preprocessed in order for the bundle algorithm to be modified without having to reload data that always remains constant. They also enable multiprocessing of threshold calculation. Parameter generation is done automatically for full datasets.\n",
    "6. Run generate_thresholds_for_given_test_cases()\n",
    "\n",
    "## For one full dataset\n",
    "1. Get relevant dataset info from get_dataset_dict()\n",
    "1. Run generate_bundle_thresholds_for_dataset() with params from step (1)\n",
    "\n",
    "## Options for bundle algorithm\n",
    "\n",
    "See documentation in .scripts.bundle_algo_base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a003d",
   "metadata": {},
   "source": [
    "## Sample code: run algorithm on test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d32fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating parameters for dataset 2016-06-13-0\n",
      "--- 2.0075643062591553 seconds ---\n",
      "Generating parameters for dataset 2016-06-13-8\n",
      "--- 0.8577167987823486 seconds ---\n",
      "Generating parameters for dataset 2016-06-13-9\n",
      "--- 0.7734551429748535 seconds ---\n",
      "Generating parameters for dataset 2017-11-20-9\n",
      "--- 0.7461609840393066 seconds ---\n",
      "Generating parameters for dataset 2020-09-12-4\n",
      "--- 0.6015815734863281 seconds ---\n",
      "Generating parameters for dataset 2020-10-06-5\n",
      "--- 1.131345510482788 seconds ---\n",
      "Generating parameters for dataset 2020-10-06-7\n",
      "--- 1.213437557220459 seconds ---\n",
      "Generating parameters for dataset 2020-10-18-5\n",
      "--- 1.743382453918457 seconds ---\n",
      "Generating parameters for dataset 2019-06-20-0\n",
      "--- 1.5548090934753418 seconds ---\n",
      "Generating parameters for dataset 2018-03-01-1\n",
      "--- 1.776806116104126 seconds ---\n",
      "Generating parameters for dataset 2019-11-07-2\n",
      "--- 2.092794895172119 seconds ---\n",
      "Generating parameters for dataset 2020-01-30-1\n",
      "--- 3.1184277534484863 seconds ---\n",
      "Generating parameters for dataset 2020-02-27-2\n"
     ]
    }
   ],
   "source": [
    "dataset_path_dict = get_dataset_dict()\n",
    "datasets_params = pregen_dataset_params(dataset_path_dict)\n",
    "\n",
    "print(\"Pregenning individual elecs...\")\n",
    "start_time = time.time()\n",
    "tests = get_bundle_test_cases(include_raphe=True, include_periphery=True, custom_tests=False)\n",
    "all_params = pregen_elec_params(tests, datasets_params, dataset_path_dict, verbose=False)\n",
    "print(\"--- %s seconds ---\\n\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6ae463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thresholds using bundle algo...\n",
      "Running bundle algorithm...\n",
      "--- 0.432680606842041 seconds ---\n",
      "\n",
      "Thresholds:\n",
      " [[ 89.  31.]\n",
      " [202.  35.]\n",
      " [330.  35.]\n",
      " [  8.  26.]\n",
      " [122.  34.]\n",
      " [102.  33.]\n",
      " [335.  33.]\n",
      " [506.  29.]\n",
      " [ 28.  27.]\n",
      " [278.  27.]\n",
      " [306.  30.]\n",
      " [483.  23.]\n",
      " [ 70.  35.]\n",
      " [232.  23.]\n",
      " [489.  18.]\n",
      " [ 17.  23.]\n",
      " [197.  24.]\n",
      " [295.   1.]\n",
      " [421.  34.]\n",
      " [ 62.  30.]\n",
      " [167.  36.]\n",
      " [341.  35.]\n",
      " [500.  37.]\n",
      " [220.  29.]\n",
      " [354.  32.]\n",
      " [477.  34.]\n",
      " [149.  18.]\n",
      " [275.  29.]\n",
      " [430.  25.]\n",
      " [489.  22.]\n",
      " [  8.  -1.]\n",
      " [ 41.  36.]\n",
      " [ 54.  34.]\n",
      " [275.  32.]\n",
      " [315.  23.]\n",
      " [364.  29.]\n",
      " [489.  29.]\n",
      " [ 88.  12.]\n",
      " [ 94.  36.]\n",
      " [353.  -1.]\n",
      " [506.  32.]\n",
      " [182.  27.]\n",
      " [460.  -1.]\n",
      " [468.  32.]\n",
      " [ 33.  28.]\n",
      " [505.  32.]\n",
      " [ 22.  24.]\n",
      " [178.  30.]\n",
      " [221.  36.]\n",
      " [448.  25.]\n",
      " [115.  36.]\n",
      " [ 58.  36.]\n",
      " [203.  31.]\n",
      " [320.  29.]\n",
      " [430.  28.]\n",
      " [498.  29.]\n",
      " [ 17.  24.]\n",
      " [ 63.  30.]\n",
      " [203.  29.]\n",
      " [313.  25.]\n",
      " [467.  31.]\n",
      " [145.  32.]\n",
      " [286.  30.]\n",
      " [405.  24.]\n",
      " [ 18.  35.]\n",
      " [108.  31.]\n",
      " [178.  32.]\n",
      " [240.  36.]\n",
      " [278.  30.]\n",
      " [339.  34.]\n",
      " [493.  29.]\n",
      " [ 95.  -1.]\n",
      " [159.  29.]\n",
      " [203.  22.]\n",
      " [305.  27.]\n",
      " [339.  24.]\n",
      " [348.  29.]]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "from scripts.bundle_criterions import *\n",
    "from scripts.bundle_algo_base import *\n",
    "print(\"Generating thresholds using bundle algo...\")\n",
    "start_time = time.time()\n",
    "thresholds = generate_thresholds_for_given_test_cases(tests, all_params, multiprocess=True, verbose=False)\n",
    "print(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "print(\"Thresholds:\\n\", thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8235f",
   "metadata": {},
   "source": [
    "## Sample code: run bundle algorithm on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aedbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_dict = get_dataset_dict()\n",
    "dataset = '2016-06-13-0'\n",
    "\n",
    "print(\"Generating thresholds for dataset \" + dataset + \"...\")\n",
    "\n",
    "vis_run = dataset_path_dict[dataset]['eidir']\n",
    "data_folder_path = dataset_path_dict[dataset]['eidir2']\n",
    "elec_run = dataset_path_dict[dataset]['seldir']\n",
    "\n",
    "analyzable_elecs = [i for i in range(519)] # if there are dead elecs, exclude this from the list, otherwise run through all elecs on array\n",
    "auto_thresholds = generate_bundle_thresholds_for_dataset(dataset, vis_run, elec_run, data_folder_path, \n",
    "                                                           analyzable_elecs)\n",
    "print(auto_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618054cd",
   "metadata": {},
   "source": [
    "## Run bundle algorithm on all data given and save to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568ae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_dict = get_dataset_dict()\n",
    "\n",
    "for dataset in dataset_path_dict.keys():\n",
    "    \n",
    "    print(\"Generating thresholds for dataset \" + dataset + \"...\")\n",
    "    vis_run = dataset_path_dict[dataset]['eidir']\n",
    "    data_folder_path = dataset_path_dict[dataset]['eidir2']\n",
    "    elec_run = dataset_path_dict[dataset]['seldir']\n",
    "\n",
    "    auto_thresholds = generate_bundle_thresholds_for_dataset(dataset, vis_run, elec_run, data_folder_path, \n",
    "                                                               analyzable_elecs)\n",
    "    print(auto_thresholds)\n",
    "\n",
    "    auto_thresholds_path = '/Volumes/Scratch/Users/huy/bundle-analysis/' + dataset + '_auto_thresholds'\n",
    "    print(\"Saving generated threshold data to path \" + auto_thresholds_path)\n",
    "    np.save(auto_thresholds_path, auto_thresholds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Huy",
   "language": "python",
   "name": "huy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
